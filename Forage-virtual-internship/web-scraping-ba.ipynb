{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# web-scraping-british-airways\n",
    "\n",
    "Use the \"Run\" button to execute the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a website and describe your objective\n",
    "\n",
    "  -  Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n",
    "  -  Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "  -  Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "\n",
    " >   We're going to scrape https://www.airlinequality.com/airline-reviews/british-airways/\n",
    " >   We'll get a list of date, country, reviews, ratings, comments.\n",
    " >   For the final data we'll create a CSV file in the following format:\n",
    "    ['date', 'country', 'reviews', 'ratings', 'comments']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_url = 'https://www.airlinequality.com/airline-reviews/british-airways/?sortby=post_date%3ADesc&pagesize=100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(reviews_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630227"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n\\n<!--[if lt IE 7]> <html class=\"no-js lt-ie9 lt-ie8 lt-ie7 lt-ie10\" lang=\"en-GB\"> <![endif]-->\\n<!--[if IE 7]>    <html class=\"no-js lt-ie9 lt-ie8 lt-ie10\" lang=\"en-GB\"> <![endif]-->\\n<!--[if IE 8]>    <html class=\"no-js lt-ie9 lt-ie10\" lang=\"en-GB\"> <![endif]-->\\n<!--[if IE 9]>    <html class=\"no-js lt-ie10\" lang=\"en-GB\"> <![endif]-->\\n<!--[if gt IE 8]><!-->\\n<html lang=\"en-GB\">\\n<!--<![endif]-->\\n\\n<head>\\n    <meta charset=\"utf-8\">\\n\\n    <title>British Airways Customer Reviews - SKYTRAX</title>\\n\\n    <!-- Google Chrome Frame for IE -->\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n\\n    <!-- mobile meta -->\\n    <meta name=\"HandheldFriendly\" content=\"True\">\\n    <meta name=\"MobileOptimized\" content=\"320\">\\n    <meta name=\"viewport\"\\n        content=\"width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no\" />\\n    <!-- icons & favicons -->\\n    <link rel=\"apple-touch-icon\" href=\"https://www.airlinequality.com/wp-content/themes/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('webpage.html', 'w') as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_class = 'text_sub_header userStatusWrapper'\n",
    "\n",
    "customer_info = doc.find_all('h3', {'class': selection_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(customer_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"text_sub_header userStatusWrapper\">\n",
       " <span itemprop=\"author\" itemscope=\"\" itemtype=\"http://schema.org/Person\">\n",
       " <span itemprop=\"name\">Pradeep Madhavan</span></span> (United Kingdom) <time datetime=\"2023-07-09\" itemprop=\"datePublished\">9th July 2023</time></h3>,\n",
       " <h3 class=\"text_sub_header userStatusWrapper\">\n",
       " <span itemprop=\"author\" itemscope=\"\" itemtype=\"http://schema.org/Person\">\n",
       " <span itemprop=\"name\">Jeffrey Rice</span></span> (United States) <time datetime=\"2023-07-09\" itemprop=\"datePublished\">9th July 2023</time></h3>,\n",
       " <h3 class=\"text_sub_header userStatusWrapper\">\n",
       " <span itemprop=\"author\" itemscope=\"\" itemtype=\"http://schema.org/Person\">\n",
       " <span itemprop=\"name\">Bridget Fagan</span></span> (United Kingdom) <time datetime=\"2023-07-08\" itemprop=\"datePublished\">8th July 2023</time></h3>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_info[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_info_1 = []\n",
    "for info in customer_info:\n",
    "    customer_info_1.append(info.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pradeep Madhavan (United Kingdom) 9th July 2023',\n",
       " 'Jeffrey Rice (United States) 9th July 2023',\n",
       " 'Bridget Fagan (United Kingdom) 8th July 2023',\n",
       " 'Bervin Hedman (United Kingdom) 6th July 2023',\n",
       " 'Alastair Cockburn (South Africa) 5th July 2023',\n",
       " 'S Carlsen (United Kingdom) 5th July 2023',\n",
       " 'A Diamantopoulos (Greece) 4th July 2023',\n",
       " 'Carlos Whilhelm (Italy) 3rd July 2023',\n",
       " 'S Warten (Senegal) 2nd July 2023',\n",
       " 'Kapil Tyagi (United States) 30th June 2023']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_info_1[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = []    # create an empty list to collect country the reviewer is from\n",
    "for info in customer_info:\n",
    "    country.append(info.span.next_sibling.strip(\" ()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United Kingdom',\n",
       " 'United States',\n",
       " 'United Kingdom',\n",
       " 'United Kingdom',\n",
       " 'South Africa',\n",
       " 'United Kingdom',\n",
       " 'Greece',\n",
       " 'Italy',\n",
       " 'Senegal',\n",
       " 'United States']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/hseju/British-Airways-Good-or-Bad/blob/main/Data%20Collection/Data-collection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to collect all reviews\n",
    "reviews  = []\n",
    "\n",
    "#create an empty list to collect all comments\n",
    "comments  = []\n",
    "\n",
    "#create an empty list to collect rating stars\n",
    "ratings = []\n",
    "\n",
    "#create an empty list to collect date\n",
    "date = []\n",
    "\n",
    "#create an empty list to collect country the reviewer is from\n",
    "country = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    page = requests.get(f\"https://www.airlinequality.com/airline-reviews/british-airways/page/{i}/?sortby=post_date%3ADesc&pagesize=100\")\n",
    "    doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "\n",
    "    #review\n",
    "    review_class = 'text_header'\n",
    "    for item in doc.find_all('h2', {'class': review_class}):\n",
    "         reviews.append(item.text)\n",
    "\n",
    "    #country\n",
    "    for item in doc.find_all(\"h3\"):\n",
    "        country.append(item.span.next_sibling.text.strip(\" ()\"))\n",
    "    \n",
    "    #comments\n",
    "    for item in doc.find_all(\"div\", class_=\"text_content\"):\n",
    "        comments.append(item.text)\n",
    "    \n",
    "    #ratings\n",
    "    for item in doc.find_all(\"div\", class_ = \"rating-10\"):\n",
    "        try:\n",
    "            ratings.append(item.span.text)\n",
    "        except:\n",
    "            print(f\"Error on page {i}\")\n",
    "            ratings.append(\"None\")\n",
    "            \n",
    "    #date\n",
    "    for item in doc.find_all(\"time\"):\n",
    "        date.append(item.text)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the length of total reviews extracted\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ratings[0], \n",
    "ratings[101],\n",
    "ratings[202],\n",
    "ratings[303],\n",
    "ratings[404],\n",
    "ratings[505],\n",
    "ratings[606],\n",
    "ratings[707],\n",
    "ratings[808],\n",
    "ratings[909])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ratings.pop(0), \n",
    "ratings.pop(100),\n",
    "ratings.pop(200),\n",
    "ratings.pop(300),\n",
    "ratings.pop(400),\n",
    "ratings.pop(500),\n",
    "ratings.pop(600),\n",
    "ratings.pop(700),\n",
    "ratings.pop(800),\n",
    "ratings.pop(900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create  a dataframe from these collected lists of data\n",
    "\n",
    "df = pd.DataFrame({\"date\":date, \"country\": country, \"reviews\": reviews, \"ratings\": ratings, \"comments\": comments})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9th July 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"Things have really deteriorated\"</td>\n",
       "      <td>4</td>\n",
       "      <td>✅ Trip Verified |  My family and I have flown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9th July 2023</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"I will never fly this airline again\"</td>\n",
       "      <td>2</td>\n",
       "      <td>✅ Trip Verified |  This has been by far the wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8th July 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"asked for an explanation but have received none\"</td>\n",
       "      <td>2</td>\n",
       "      <td>✅ Trip Verified |  In Nov 2022 I booked and pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6th July 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"short-changing passengers\"</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Verified | BA is not treating its premium ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th July 2023</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>\"Economy is absolutely awful\"</td>\n",
       "      <td>1</td>\n",
       "      <td>✅ Trip Verified |  24 hours before our departu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>18th March 2023</td>\n",
       "      <td>India</td>\n",
       "      <td>\"Very impressive and efficient\"</td>\n",
       "      <td>8</td>\n",
       "      <td>✅ Trip Verified | First time flying with Briti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>18th March 2023</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"We are done with BA\"</td>\n",
       "      <td>3</td>\n",
       "      <td>✅ Trip Verified |  The latest affront. Stood i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>17th March 2023</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"I was left stranded at the airport\"</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Verified |  Booked a flight return flight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>17th March 2023</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>\"I will never fly with them again\"</td>\n",
       "      <td>1</td>\n",
       "      <td>✅ Trip Verified |  I tried to check in on line...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>16th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"A catalogue of failures\"</td>\n",
       "      <td>1</td>\n",
       "      <td>✅ Trip Verified |  A catalogue of failures. We...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date         country  \\\n",
       "0      9th July 2023  United Kingdom   \n",
       "1      9th July 2023   United States   \n",
       "2      8th July 2023  United Kingdom   \n",
       "3      6th July 2023  United Kingdom   \n",
       "4      5th July 2023    South Africa   \n",
       "..               ...             ...   \n",
       "995  18th March 2023           India   \n",
       "996  18th March 2023   United States   \n",
       "997  17th March 2023   United States   \n",
       "998  17th March 2023     Netherlands   \n",
       "999  16th March 2023  United Kingdom   \n",
       "\n",
       "                                               reviews ratings  \\\n",
       "0                    \"Things have really deteriorated\"       4   \n",
       "1                \"I will never fly this airline again\"       2   \n",
       "2    \"asked for an explanation but have received none\"       2   \n",
       "3                          \"short-changing passengers\"       4   \n",
       "4                        \"Economy is absolutely awful\"       1   \n",
       "..                                                 ...     ...   \n",
       "995                    \"Very impressive and efficient\"       8   \n",
       "996                              \"We are done with BA\"       3   \n",
       "997               \"I was left stranded at the airport\"       1   \n",
       "998                 \"I will never fly with them again\"       1   \n",
       "999                          \"A catalogue of failures\"       1   \n",
       "\n",
       "                                              comments  \n",
       "0    ✅ Trip Verified |  My family and I have flown ...  \n",
       "1    ✅ Trip Verified |  This has been by far the wo...  \n",
       "2    ✅ Trip Verified |  In Nov 2022 I booked and pa...  \n",
       "3    Not Verified | BA is not treating its premium ...  \n",
       "4    ✅ Trip Verified |  24 hours before our departu...  \n",
       "..                                                 ...  \n",
       "995  ✅ Trip Verified | First time flying with Briti...  \n",
       "996  ✅ Trip Verified |  The latest affront. Stood i...  \n",
       "997  Not Verified |  Booked a flight return flight ...  \n",
       "998  ✅ Trip Verified |  I tried to check in on line...  \n",
       "999  ✅ Trip Verified |  A catalogue of failures. We...  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data into a csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('british_airways_reviews.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}